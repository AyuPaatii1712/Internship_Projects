{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a02e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aba84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db265ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Hotel_Review\\\\model_building_dataset1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8680/2083960841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hotel_Review\\model_building_dataset1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Hotel_Review\\\\model_building_dataset1.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('model_building_dataset1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86208288",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b69f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30952f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectKBest(score_func=chi2, k='all')\n",
    "fit = model.fit(data.iloc[:,1:], data.iloc[:,0])\n",
    "scores = np.around(fit.scores_, 3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229abdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cols = list(np.where(scores>0.5)[0])\n",
    "idx_cols = [x+1 for x in idx_cols]\n",
    "idx_cols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a117b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.iloc[:,0],data.iloc[:,idx_cols]], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c25ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818b1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6d95a6",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8907628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e46cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228ceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a48562",
   "metadata": {},
   "source": [
    "## 1).Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da867a6",
   "metadata": {},
   "source": [
    "+ Since we are going to use One Vs Rest algorithm, set **multi_class='ovr'**\n",
    "+ Note: since we are using One Vs Rest algorithm we must use **'liblinear' solver** with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ddf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', multi_class='ovr', solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b78371",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c01af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report: \\n',classification_report(y_test, y_test_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbc54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e5c6a7",
   "metadata": {},
   "source": [
    "## 2).K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94c109",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Plot\n",
    "acc = []\n",
    "for k in range(1, 11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train , y_train)\n",
    "    y_predict = knn.predict(X_train)\n",
    "    acc.append(accuracy_score(y_train , y_predict))\n",
    "    \n",
    "plt.plot(range(1, 11), acc)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Neighbour')\n",
    "plt.ylabel('ACCURACY')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter Value\n",
    "kfold = KFold()\n",
    "n_neighbors = np.array(range(1,10))\n",
    "param_grid = {'n_neighbors':n_neighbors}\n",
    "\n",
    "# Hyper parameter tunning using GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = kfold, n_jobs=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb54766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2f25c",
   "metadata": {},
   "source": [
    "### K-NN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef04b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=para['n_neighbors'])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7146b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b53ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06de912a",
   "metadata": {},
   "source": [
    "## 3).Naive Bayes classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04705655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, data.iloc[:,1:], data.iloc[:,0], cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab694a",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter Value\n",
    "kfold = KFold()\n",
    "alpha = np.arange(0.1, 1.1, 0.1)\n",
    "param_grid = {'alpha':alpha}\n",
    "\n",
    "# Hyper parameter tunning using GridSearchCV\n",
    "model = MultinomialNB()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid , cv = kfold, n_jobs=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3edd5",
   "metadata": {},
   "source": [
    "### Naive Bayes Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=para['alpha'])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6abdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afec9358",
   "metadata": {},
   "source": [
    "## 4). Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65723321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import  DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6172d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "result = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "result.mean()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa5b79",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e082aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['entropy','gini'] ,'max_depth': [2,4,6,8,10,12], 'min_samples_split': [2,3,4]}\n",
    "\n",
    "model_test = DecisionTreeClassifier()\n",
    "gcv = GridSearchCV(estimator=model_test,param_grid=params)\n",
    "gcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gcv.best_score_)\n",
    "print(gcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73483a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1baea7a",
   "metadata": {},
   "source": [
    "### Decision Tree Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion=para['criterion'], max_depth=para['max_depth'], \n",
    "                               min_samples_split=para['min_samples_split'])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('Training Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_train, y_train_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_train, y_train_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_train, y_train_pred, average='weighted'),3))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('\\nTesting Scores:-')\n",
    "print('Accuracy Score: ',round(accuracy_score(y_test, y_test_pred),3))\n",
    "print('F1 Score: ',round(f1_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Precision Score: ',round(precision_score(y_test, y_test_pred, average='weighted'),3))\n",
    "print('Recall Score: ',round(recall_score(y_test, y_test_pred, average='weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af113572",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f', linewidths=1)\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Training Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "dt = {'Negative':list(cm[0]), 'Neutral':list(cm[1]), 'Positive':list(cm[2])}\n",
    "cm_df = pd.DataFrame(dt, index=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df,annot=True,fmt='.0f')\n",
    "plt.ylabel('Predictions', fontsize=18)\n",
    "plt.xlabel('Actuals', fontsize=18)\n",
    "plt.title('Testing Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557936e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
